{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de912bb0",
   "metadata": {},
   "source": [
    "El dataset con el que estamos trabajando es de una campaña de marketing telefónica de una institución bancaria. El objetivo es predecir si un cliente suscribirá o no un depósito a plazo (la variable y). Esta información es crucial para el banco, ya que un depósito a plazo es una fuente importante de ingresos y requiere inversión en campañas de marketing.\n",
    "\n",
    "Descripción de los Atributos del Dataset\n",
    "Aquí tienes una descripción detallada de cada atributo:\n",
    "\n",
    "* age: Edad del cliente. (Numérico)\n",
    "\n",
    "* job: Tipo de empleo del cliente. Las categorías incluyen:\n",
    "\n",
    "\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\", \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\", \"retired\", \"technician\", \"services\". (Categórico)\n",
    "* marital: Estado civil del cliente. Las categorías incluyen:\n",
    "\n",
    "\"married\", \"divorced\" (incluye personas viudas), \"single\". (Categórico)\n",
    "*education: Nivel educativo del cliente. Las categorías incluyen:\n",
    "\n",
    "\"unknown\", \"secondary\", \"primary\", \"tertiary\". (Categórico)\n",
    "* default: Indica si el cliente tiene crédito en mora. (Binario: \"yes\", \"no\")\n",
    "\n",
    "* balance: Balance promedio anual del cliente en la cuenta bancaria, en euros. (Numérico)\n",
    "\n",
    "* housing: Indica si el cliente tiene un préstamo hipotecario. (Binario: \"yes\", \"no\")\n",
    "\n",
    "* loan: Indica si el cliente tiene un préstamo personal. (Binario: \"yes\", \"no\")\n",
    "\n",
    "** Atributos Relacionados con la Última Campaña de Contacto\n",
    "* contact: Tipo de comunicación utilizada en la última campaña de contacto. Las opciones son:\n",
    "\n",
    "\"unknown\", \"telephone\", \"cellular\". (Categórico)\n",
    "* day: Día del mes en que se realizó el último contacto con el cliente. (Numérico)\n",
    "\n",
    "* month: Mes en que se realizó el último contacto con el cliente. (Categórico: \"jan\", \"feb\", \"mar\", …, \"nov\", \"dec\")\n",
    "\n",
    "* duration: Duración de la última llamada en segundos. (Numérico)\n",
    "\n",
    "Nota: Esta variable tiene un impacto directo en el objetivo. En general, una mayor duración puede indicar un mayor interés en el producto.\n",
    "** Otros Atributos\n",
    "* campaign: Número de contactos realizados durante la campaña para este cliente, incluido el último contacto. (Numérico)\n",
    "\n",
    "* pdays: Número de días desde el último contacto del cliente en una campaña anterior. (Numérico)\n",
    "\n",
    "Un valor de -1 indica que el cliente no fue contactado previamente.\n",
    "* previous: Número de contactos realizados antes de esta campaña para este cliente. (Numérico)\n",
    "\n",
    "* poutcome: Resultado de la campaña de marketing anterior. Las categorías incluyen:\n",
    "\n",
    "\"unknown\", \"other\", \"failure\", \"success\". (Categórico)\n",
    "* Variable Objetivo\n",
    "y: Indica si el cliente suscribió un depósito a plazo en esta campaña de marketing. (Binario: \"yes\", \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d49bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_curve, auc,precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "file_path = 'dataset.csv'\n",
    "data = pd.read_csv(file_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del dataset\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6afd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276fb70",
   "metadata": {},
   "source": [
    "el dataset es completo, ya que no tiene valores faltantes. Además, la mayoría de las columnas están en formato object, lo cual es típico para variables categóricas. Las columnas en int64 son numéricas y pueden ser continuas o discretas, dependiendo de su naturaleza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar datos faltantes\n",
    "print(\"\\nDatos faltantes por columna:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113a4c2",
   "metadata": {},
   "source": [
    "Estadísticas Descriptivas\n",
    "count: Número de valores no nulos en cada columna. En este caso, todas las columnas tienen 45211 valores no nulos, lo que confirma que no hay valores faltantes en las columnas numéricas.\n",
    "\n",
    "mean: La media (promedio) de los valores de cada columna.\n",
    "\n",
    "std: La desviación estándar, que mide la dispersión de los datos alrededor de la media. Un valor alto indica que los datos están más dispersos.\n",
    "\n",
    "min: El valor mínimo en cada columna.\n",
    "\n",
    "25%: El primer cuartil, que representa el valor por debajo del cual se encuentra el 25% de los datos.\n",
    "\n",
    "50%: La mediana (o segundo cuartil), que es el valor central de los datos. Es el punto donde el 50% de los datos están por debajo y el otro 50% están por encima.\n",
    "\n",
    "75%: El tercer cuartil, que representa el valor por debajo del cual se encuentra el 75% de los datos.\n",
    "\n",
    "max: El valor máximo en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribución de la variable objetivo (y):\")\n",
    "print(data['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92303e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas numéricas\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Configurar el estilo de las gráficas\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Histograma y boxplot para cada variable numérica\n",
    "for col in numerical_columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Histograma\n",
    "    sns.histplot(data[col], kde=True, ax=axes[0])\n",
    "    axes[0].set_title(f'Distribución de {col}')\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # Boxplot\n",
    "    sns.boxplot(x=data[col], ax=axes[1])\n",
    "    axes[1].set_title(f'Boxplot de {col}')\n",
    "    axes[1].set_xlabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f9c01",
   "metadata": {},
   "source": [
    "La distribución de la edad tiene un sesgo hacia la derecha, lo que significa que la mayoría de los clientes son relativamente jóvenes o de mediana edad.\n",
    "La mayor concentración de clientes parece estar en el rango de 30 a 40 años, con un pico significativo en torno a los 30 años.\n",
    "La frecuencia disminuye a medida que aumenta la edad, especialmente a partir de los 50 años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = data[numerical_columns]\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Graficar el mapa de calor de la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, square=True)\n",
    "plt.title('Matriz de Correlación entre Variables Numéricas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d83275",
   "metadata": {},
   "source": [
    "La mayoría de los valores de correlación están cerca de 0, lo que indica que la mayoría de las variables numéricas no tienen una fuerte relación entre sí. Esto significa que estos atributos son, en su mayoría, independientes entre sí en términos de correlación lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas categóricas\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Configurar el estilo de las gráficas\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Gráfico de barras para cada variable categórica\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(data=data, x=col, order=data[col].value_counts().index)\n",
    "    plt.title(f'Distribución de la Variable Categórica: {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1da285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de normalidad Shapiro-Wilk para cada columna numérica\n",
    "normality_results = {}\n",
    "for col in numerical_columns:\n",
    "    stat, p_value = stats.shapiro(data[col].dropna())\n",
    "    normality_results[col] = {'Statistic': stat, 'p-value': p_value}\n",
    "\n",
    "# Mostrar los resultados\n",
    "normality_df = pd.DataFrame(normality_results).T\n",
    "print(\"Resultados de la Prueba de Normalidad Shapiro-Wilk:\")\n",
    "print(normality_df)\n",
    "\n",
    "# Interpretación de resultados\n",
    "alpha = 0.05\n",
    "for col in normality_results:\n",
    "    if normality_results[col]['p-value'] > alpha:\n",
    "        print(f\"{col}: No se rechaza la hipótesis nula (distribución normal)\")\n",
    "    else:\n",
    "        print(f\"{col}: Se rechaza la hipótesis nula (no sigue una distribución normal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d14ca",
   "metadata": {},
   "source": [
    "Statistic (Estadístico de Shapiro-Wilk):\n",
    "\n",
    "El estadístico de Shapiro-Wilk es un valor que indica el ajuste de los datos a una distribución normal. Este valor varía entre 0 y 1.\n",
    "Un valor cercano a 1 indica que los datos se ajustan bien a una distribución normal.\n",
    "Valores menores indican una menor adecuación de los datos a la normalidad. Sin embargo, por sí solo no es suficiente para rechazar o aceptar la hipótesis de normalidad; para eso se usa el p-value.\n",
    "p-value (Valor p):\n",
    "\n",
    "El p-value es el valor de probabilidad asociado a la prueba de hipótesis de normalidad.\n",
    "La hipótesis nula (H0) en esta prueba es que los datos tienen una distribución normal.\n",
    "Interpretación del p-value:\n",
    "Si el p-value es menor que el nivel de significancia (generalmente 0.05), se rechaza la hipótesis nula, indicando que los datos no siguen una distribución normal.\n",
    "Si el p-value es mayor o igual al nivel de significancia, no se rechaza la hipótesis nula, lo cual sugiere que los datos podrían seguir una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear gráficos Q-Q para cada variable numérica\n",
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    stats.probplot(data[col].dropna(), dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Gráfico Q-Q de {col}')\n",
    "    plt.xlabel('Cuantiles Teóricos')\n",
    "    plt.ylabel('Cuantiles de los Datos')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d97911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning de 'age'\n",
    "data['age_group'] = pd.cut(data['age'], bins=[0, 30, 60, 100], labels=['joven', 'adulto', 'mayor'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080a127",
   "metadata": {},
   "source": [
    "Se utiliza la función pd.cut() de pandas para dividir la variable age en categorías o grupos de edades, y luego asigna una etiqueta (como joven, adulto, mayor) a cada grupo. Aquí está el desglose de cada parámetro:\n",
    "\n",
    "Explicación de los Parámetros\n",
    "data['age']: Es la columna que se va a categorizar. En este caso, la columna age contiene la edad de los clientes.\n",
    "\n",
    "bins=[0, 30, 60, 100]: Define los límites de los intervalos para categorizar las edades. Cada par de números en bins representa un rango que formará un grupo:\n",
    "\n",
    "[0, 30) agrupa las edades entre 0 y 30 años, sin incluir el 30.\n",
    "[30, 60) agrupa las edades entre 30 y 60 años, sin incluir el 60.\n",
    "[60, 100] agrupa las edades entre 60 y 100 años, incluyendo el 100.\n",
    "labels=['joven', 'adulto', 'mayor']: Asigna una etiqueta a cada intervalo. En este caso:\n",
    "\n",
    "joven se asignará a los valores de age entre 0 y 30 años.\n",
    "adulto se asignará a los valores de age entre 30 y 60 años.\n",
    "mayor se asignará a los valores de age entre 60 y 100 años.\n",
    "data['age_group']: Crea una nueva columna en el DataFrame llamada age_group que contendrá las etiquetas asignadas a cada cliente según su edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e62ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform en 'balance'\n",
    "data['log_balance'] = np.log1p(data['balance'])  # np.log1p para evitar log(0)\n",
    "\n",
    "# Crear interacción entre 'balance' y 'loan'\n",
    "data['balance_loan_interaction'] = data['balance'] * data['loan'].apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b24f8d",
   "metadata": {},
   "source": [
    "Un logaritmo es una forma de responder a la pregunta: “¿A qué número debo elevar una base para obtener un cierto valor?”\n",
    "\n",
    "Ejemplo Básico\n",
    "Si pensamos en el logaritmo en base 10, que es común en muchos contextos, el logaritmo nos dice cuántas veces tenemos que multiplicar el número 10 para obtener un valor específico.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "El logaritmo de 1000 en base 10 es 3, porque 10 elevado a la 3 es igual a 1000 (o sea, \n",
    "10\n",
    "×\n",
    "10\n",
    "×\n",
    "10\n",
    "=\n",
    "1000).\n",
    "De manera similar, el logaritmo de 100 en base 10 es 2, porque 10 elevado a la 2 es igual a 100.\n",
    "En notación matemática, esto se escribiría como:\n",
    "\n",
    "log\n",
    "⁡\n",
    "10\n",
    "(\n",
    "1000\n",
    ")\n",
    "=\n",
    "3\n",
    "log \n",
    "10\n",
    "​\n",
    " (1000)=3\n",
    "Lo que significa: “El logaritmo en base 10 de 1000 es 3”.\n",
    "\n",
    "¿Para Qué se Usa?\n",
    "Simplificar Números Grandes: Los logaritmos se usan para convertir números grandes en números más manejables. Por ejemplo, el logaritmo de un millón (1,000,000) en base 10 es 6, porque 10 elevado a la 6 es 1,000,000.\n",
    "\n",
    "Modelar Crecimiento y Decadencia: Los logaritmos son útiles para describir procesos donde el crecimiento o la disminución no es lineal, como el crecimiento de poblaciones, la intensidad del sonido, o el crecimiento de una inversión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae4f7e",
   "metadata": {},
   "source": [
    "Transformación logarítmica:\n",
    "\n",
    "np.log1p() aplica el logaritmo natural a balance + 1. La expresión log1p(x) es equivalente a log(x + 1).\n",
    "Esta transformación es útil cuando quieres reducir la escala de los valores y hacer que la distribución sea más simétrica, especialmente si la variable balance está sesgada (por ejemplo, con una larga cola hacia la derecha)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6042e02",
   "metadata": {},
   "source": [
    "balance_loan_interaction en el DataFrame es una variable de interacción que combina la información del balance (balance) y del estado de préstamo (loan). Aquí se multiplica el balance por un valor binario basado en si el cliente tiene un préstamo personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b717102",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f525f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las variables numéricas a transformar con MinMaxScaler, excluyendo age, log_balance, y balance_loan_interaction\n",
    "numerical_features_to_scale = ['balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Aplicar Min-Max Scaling solo a las variables seleccionadas\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical_data = pd.DataFrame(scaler.fit_transform(data[numerical_features_to_scale]), columns=numerical_features_to_scale)\n",
    "\n",
    "# Reemplazar -inf y NaN en log_balance con el mínimo valor de log_balance sin -inf ni NaN\n",
    "min_log_balance = data['log_balance'].replace([-np.inf, np.nan], np.nan).min()\n",
    "\n",
    "\n",
    "# Agregar log_balance y balance_loan_interaction al dataset de variables numéricas transformadas\n",
    "scaled_numerical_data['log_balance'] = data['log_balance'].replace([-np.inf, np.nan], min_log_balance)\n",
    "scaled_numerical_data['balance_loan_interaction'] = data['balance_loan_interaction']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4a2ef",
   "metadata": {},
   "source": [
    "¿Por qué NaN y -inf?:\n",
    "\n",
    "NaN: Cuando balance es tan bajo que balance + 1 da un valor negativo (por ejemplo, para balance = -8019), np.log1p() devuelve NaN porque el logaritmo de un número negativo no está definido.\n",
    "-inf: Si el valor de balance es -1, entonces balance + 1 es 0, y np.log1p(0) es -inf porque el logaritmo de cero tiende a infinito negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variables categóricas, incluyendo age_group\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'age_group']\n",
    "\n",
    "# Aplicar One-Hot Encoding a las variables categóricas\n",
    "categorical_data = pd.get_dummies(data[categorical_features], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3dc04",
   "metadata": {},
   "source": [
    "get_dummies convierte las variables categóricas en el DataFrame data a una representación numérica \"dummy\" o \"one-hot encoding\", lo cual es necesario para que los modelos de machine learning puedan procesarlas correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61835c6e",
   "metadata": {},
   "source": [
    "La multicolinealidad es una situación en la que dos o más variables independientes en un modelo de regresión están altamente correlacionadas entre sí, lo cual puede causar problemas en el análisis y en la interpretación de los resultados del modelo.\n",
    "\n",
    "Cuando existe multicolinealidad, significa que algunas variables independientes (predictores) en el modelo aportan información redundante, porque están tan relacionadas entre sí que prácticamente contienen la misma información. Esto puede hacer que el modelo sea menos estable y los coeficientes de las variables independientes menos confiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la variable objetivo\n",
    "target = data[['y']]\n",
    "\n",
    "# Crear el dataset final combinando numéricas, categóricas y la variable objetivo\n",
    "final_dataset = pd.concat([scaled_numerical_data, categorical_data, target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la distribución de la variable objetivo\n",
    "print(\"Distribución de la variable objetivo (y):\")\n",
    "print(data['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = final_dataset.drop(columns=['y'])\n",
    "y = final_dataset['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Convertir 'yes' a 1 y 'no' a 0 para SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE solo al conjunto de entrenamiento imputado\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificar la nueva distribución de la clase en el conjunto de entrenamiento balanceado\n",
    "print(\"Distribución después de aplicar SMOTE en el conjunto de entrenamiento:\")\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fe5939",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique) es una técnica utilizada para balancear conjuntos de datos desbalanceados mediante la creación de muestras sintéticas de la clase minoritaria. Es especialmente útil en problemas de clasificación donde una de las clases tiene muchas menos observaciones que la otra, lo que puede llevar a que los modelos de machine learning no aprendan correctamente las características de la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e841b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de Árbol de Decisión\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a32eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a99e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nExactitud (Accuracy):\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7fbf43e7",
   "metadata": {},
   "source": [
    "matriz se interpreta de la siguiente manera:\n",
    "\n",
    "Clase 0 (predicciones negativas, probablemente la clase mayoritaria):\n",
    "\n",
    "* 7078: Verdaderos Negativos (TN): Casos que son realmente de la clase 0 y el modelo los predijo correctamente como clase 0.\n",
    "* 907: Falsos Positivos (FP): Casos que son realmente de la clase 1, pero el modelo los predijo incorrectamente como clase 0.\n",
    "\n",
    "Clase 1 (predicciones positivas, probablemente la clase minoritaria):\n",
    "\n",
    "* 493: Falsos Negativos (FN): Casos que son realmente de la clase 1, pero el modelo los predijo incorrectamente como clase 0.\n",
    "* 565: Verdaderos Positivos (TP): Casos que son realmente de la clase 1 y el modelo los predijo correctamente como clase 1.\n",
    "\n",
    "\n",
    "Precision:\n",
    "\n",
    "* Indica el porcentaje de predicciones positivas que son correctas.\n",
    "* Para la clase 0, la precisión es de 0.93. Esto significa que el 93% de las veces que el modelo predijo la clase 0, esa predicción fue correcta.\n",
    "* Para la clase 1, la precisión es de 0.38. Esto significa que el 38% de las veces que el modelo predijo la clase 1, esa predicción fue correcta.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "Recall:\n",
    "\n",
    "* Indica el porcentaje de casos reales de una clase que fueron correctamente identificados.\n",
    "* Para la clase 0, el recall es de 0.89, lo que significa que el modelo identificó correctamente el 89% de todos los casos reales de clase 0.\n",
    "* Para la clase 1, el recall es de 0.53, lo que significa que el modelo identificó correctamente el 53% de todos los casos reales de clase 1.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "\n",
    "F1-Score:\n",
    "\n",
    "* Es la media armónica de la precisión y el recall. El F1-score equilibra estas dos métricas y es especialmente útil en conjuntos de datos desbalanceados.\n",
    "* Para la clase 0, el F1-score es 0.91.\n",
    "* Para la clase 1, el F1-score es 0.45.\n",
    "\n",
    "\n",
    "Support:\n",
    "\n",
    "* Es el número de ocurrencias reales de cada clase en el conjunto de prueba.\n",
    "* La clase 0 tiene un soporte de 7985 casos, y la clase 1 tiene un soporte de 1058 casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d969f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del tamaño del gráfico\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Graficar el árbol\n",
    "plot_tree(clf, filled=True, feature_names=X_train_balanced.columns, class_names=['No', 'Yes'], rounded=True, proportion=True)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo base\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Definir los parámetros a evaluar\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda en cuadrícula\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Mostrar los mejores parámetros y el mejor puntaje\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor F1-score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c2e44",
   "metadata": {},
   "source": [
    "Hiperparámetro\n",
    "\n",
    "### max_depth:\n",
    "\n",
    "Controla la profundidad máxima del árbol de decisión.\n",
    "Valores: [3, 5, 10, None]\n",
    "3, 5, 10: Limita el árbol a esas profundidades específicas.\n",
    "None: No limita la profundidad, permitiendo que el árbol crezca hasta que todas las hojas sean puras o hasta que se alcance min_samples_split.\n",
    "Propósito: Limitar la profundidad puede ayudar a evitar el sobreajuste (overfitting) al reducir la complejidad del árbol.\n",
    "\n",
    "### min_samples_split:\n",
    "Define el número mínimo de muestras necesarias para dividir un nodo.\n",
    "Valores: [2, 5, 10]\n",
    "2: Permite dividir un nodo si tiene al menos 2 muestras.\n",
    "5, 10: Requiere al menos 5 o 10 muestras para dividir un nodo.\n",
    "Propósito: Ayuda a controlar la cantidad de nodos en el árbol. Valores más altos pueden prevenir el sobreajuste al impedir que el modelo cree demasiados nodos en ramas con pocas muestras.\n",
    "\n",
    "###  min_samples_leaf:\n",
    "Define el número mínimo de muestras que debe tener una hoja.\n",
    "Valores: [1, 5, 10]\n",
    "1: Permite hojas con una sola muestra.\n",
    "5, 10: Requiere que las hojas tengan al menos 5 o 10 muestras.\n",
    "Propósito: Ayuda a suavizar el modelo. Establecer un número mínimo más alto evita que el modelo cree hojas para casos aislados, reduciendo el riesgo de sobreajuste.\n",
    "\n",
    "###  max_features:\n",
    "Define el número máximo de características a considerar al buscar la mejor división.\n",
    "Valores: ['auto', 'sqrt', 'log2', None]\n",
    "'auto': Usa todas las características (en este caso es equivalente a None para DecisionTreeClassifier).\n",
    "'sqrt': Usa la raíz cuadrada del número total de características.\n",
    "'log2': Usa el logaritmo en base 2 del número total de características.\n",
    "None: Usa todas las características disponibles.\n",
    "Propósito: Limitar el número de características para cada división puede hacer que el modelo sea más robusto y menos propenso a ajustarse demasiado a una sola característica. Este hiperparámetro es especialmente útil para árboles en modelos de conjunto (ensemble) como Random Forest.\n",
    "\n",
    "### criterion:\n",
    "Define la métrica que el árbol de decisión utiliza para evaluar la calidad de una división.\n",
    "Valores: ['gini', 'entropy']\n",
    "'gini': Utiliza el índice de Gini para medir la \"impureza\" de las divisiones. Prefiere ramas con clases puras.\n",
    "'entropy': Utiliza la entropía como criterio de impureza, que proviene de la teoría de la información. Tiende a crear árboles ligeramente más profundos.\n",
    "Propósito: El criterio afecta la estructura del árbol; ambos son métodos para medir la calidad de una división, aunque producen resultados similares en la mayoría de los casos.\n",
    "\n",
    "### class_weight:\n",
    "Ajusta el peso de cada clase para contrarrestar el desbalance de clases.\n",
    "Valores: [None, 'balanced']\n",
    "None: No ajusta los pesos; todas las clases tienen el mismo peso.\n",
    "'balanced': Ajusta automáticamente los pesos de las clases en función de su frecuencia, dándole mayor peso a la clase minoritaria.\n",
    "Propósito: En problemas de clasificación desbalanceada, establecer class_weight='balanced' ayuda al modelo a prestar más atención a la clase minoritaria, mejorando el rendimiento en esa clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17283b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de árbol de decisión con los mejores hiperparámetros y max_depth=10\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "clf.fit(X_train_balanced, y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nExactitud (Accuracy):\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe8494",
   "metadata": {},
   "source": [
    "* En el nuevo modelo, el recall de la clase 1 mejoró, lo que significa que el modelo es mejor identificando los casos positivos de la clase 1. Esto es útil si el objetivo es captar más de esta clase.\n",
    "* Sin embargo, esto se logró a costa de reducir la precisión y recall de la clase 0 y reducir ligeramente el accuracy general.\n",
    "* La mejora en el recall de la clase 1 puede ser deseable en escenarios donde es crucial detectar la clase minoritaria, incluso si eso significa un ligero sacrificio en la precisión general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f013e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del tamaño del gráfico\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Graficar el árbol\n",
    "plot_tree(clf, filled=True, feature_names=X_train_balanced.columns, class_names=['No', 'Yes'], rounded=True, proportion=True)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las probabilidades de predicción para la clase positiva\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular la Curva ROC y AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la Curva ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Línea de referencia\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC del Modelo de Árbol de Decisión')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b420b",
   "metadata": {},
   "source": [
    "La Curva ROC (Receiver Operating Characteristic) es una herramienta gráfica utilizada para evaluar el rendimiento de un modelo de clasificación binaria. \n",
    "\n",
    "La curva ROC representa la relación entre dos métricas:\n",
    "\n",
    "* FPR (False Positive Rate) - Tasa de Falsos Positivos:\n",
    "\n",
    "Indica la proporción de casos negativos que fueron clasificados incorrectamente como positivos.\n",
    "Va en el eje X de la gráfica.\n",
    "Valores bajos de FPR indican que el modelo es bueno para evitar clasificar incorrectamente los casos negativos.\n",
    "\n",
    "* TPR (True Positive Rate) - Tasa de Verdaderos Positivos o Sensibilidad (también llamado Recall):\n",
    "\n",
    "Indica la proporción de casos positivos que fueron clasificados correctamente.\n",
    "\n",
    "Va en el eje Y de la gráfica.\n",
    "Valores altos de TPR indican que el modelo es bueno para detectar casos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161ff3d",
   "metadata": {},
   "source": [
    "Interpretación de la Curva ROC\n",
    "\n",
    "## Línea Diagonal (Línea de Azar):\n",
    "\n",
    "* La línea diagonal punteada representa un modelo que clasifica aleatoriamente, donde FPR y TPR son iguales.\n",
    "* Un modelo que cae sobre esta línea no tiene capacidad predictiva y no es mejor que un modelo de predicción aleatoria.\n",
    "\n",
    "## Curva ROC del Modelo:\n",
    "\n",
    "* La curva ROC muestra cómo cambian la TPR y la FPR a medida que el umbral de decisión del modelo cambia.\n",
    "* Un modelo perfecto alcanzaría la esquina superior izquierda (FPR = 0, TPR = 1), ya que esto indica una TPR del 100% y una FPR del 0%.\n",
    "## Área Bajo la Curva (AUC - Area Under the Curve):\n",
    "* El valor AUC mide el área bajo la curva ROC.\n",
    "* AUC varía entre 0 y 1:\n",
    "* AUC = 1: Modelo perfecto.\n",
    "* AUC = 0.5: Modelo sin capacidad de discriminación (equivalente a una clasificación aleatoria).\n",
    "* AUC < 0.5: Indica un modelo peor que uno aleatorio, lo que rara vez sucede.\n",
    "* En este caso, el AUC es 0.81, lo que indica que el modelo tiene un buen desempeño, ya que 0.81 es significativamente mayor que 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c83626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las probabilidades de predicción para la clase positiva\n",
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular la curva de precisión-recall y AUC para la clase positiva (y = 1)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "# Graficar la curva de precisión-recall para la clase positiva\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, color='blue', label=f'Clase Positiva (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Curva de Precisión-Recall para la Clase Positiva')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fb39d",
   "metadata": {},
   "source": [
    "Esta es una Curva de Precisión-Recall para la clase positiva de un modelo de clasificación. Esta curva es útil para evaluar el rendimiento del modelo, especialmente en problemas con clases desbalanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e91b43",
   "metadata": {},
   "source": [
    "Interpretación de la Curva de Precisión-Recall\n",
    "* La curva muestra cómo varían la precisión y el recall a medida que cambia el umbral de decisión del modelo.\n",
    "* A medida que el recall aumenta (es decir, el modelo identifica más casos positivos correctamente), la precisión tiende a disminuir. Esto ocurre porque, para lograr un mayor recall, el modelo empieza a clasificar más casos como positivos, lo que también puede aumentar los falsos positivos.\n",
    "* La curva comienza con una alta precisión cuando el recall es bajo, y a medida que se incrementa el recall, la precisión disminuye.\n",
    "\n",
    "\n",
    "* La curva muestra que el modelo tiene una alta precisión cuando el recall es bajo, pero a medida que intenta capturar más casos positivos (aumentando el recall), la precisión disminuye de manera significativa.\n",
    "* El Average Precision (AP) de 0.41 sugiere que el modelo tiene un rendimiento moderado en términos de mantener precisión y recall balanceados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
