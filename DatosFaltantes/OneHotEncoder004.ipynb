{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81ea7fc-ff8b-470d-9065-26d083f852ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\gabriel.guzman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\gabriel.guzman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\gabriel.guzman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gabriel.guzman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gabriel.guzman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba9669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabriel Guzmán - CSV\n",
      "\n",
      "DataFrame original:\n",
      "    age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
      "\n",
      "Precisión del modelo (accuracy): 0.8462899480260976\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      7952\n",
      "           1       0.43      0.82      0.56      1091\n",
      "\n",
      "    accuracy                           0.85      9043\n",
      "   macro avg       0.70      0.84      0.74      9043\n",
      "weighted avg       0.91      0.85      0.87      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Kodigo\n",
    "print(\"Gabriel Guzmán - CSV\\n\")\n",
    "\n",
    "# Cargar el archivo CSV desde GitHub\n",
    "url = \"https://raw.githubusercontent.com/nzepedacc/Pandas/main/bank-full.csv\"\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(\"DataFrame original:\\n\", df.head())\n",
    "\n",
    "# ----------------- SEPARAR VARIABLES DEPENDIENTE E INDEPENDIENTES -----------------\n",
    "# El objetivo es predecir la columna 'y' (si el cliente aceptó el depósito)\n",
    "X = df.drop(columns=['y'])  # Variables predictoras\n",
    "y = df['y']  # Variable objetivo\n",
    "\n",
    "# Convertir la variable objetivo a binaria (yes=1, no=0)\n",
    "y = y.map({'yes': 1, 'no': 0})\n",
    "\n",
    "# ----------------- CREAR EL PIPELINE -----------------\n",
    "# Seleccionar características numéricas y categóricas\n",
    "numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "# Pipeline para columnas numéricas: imputar valores faltantes y escalar\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputar valores faltantes con la media\n",
    "    ('scaler', StandardScaler())  # Escalar las columnas numéricas\n",
    "])\n",
    "\n",
    "# Pipeline para columnas categóricas: imputar valores faltantes y aplicar One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),  # Imputar valores faltantes con 'Unknown'\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Aplicar One-Hot Encoding\n",
    "])\n",
    "\n",
    "# Usar ColumnTransformer para aplicar las transformaciones correspondientes a cada tipo de columna\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------- APLICAR TRANSFORMACIONES ANTES DE SMOTE -----------------\n",
    "# Aplicar las transformaciones (One-Hot Encoding y escalado) en el conjunto de entrenamiento\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Aplicar SMOTE para balancear el conjunto de entrenamiento transformado\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# ----------------- ENTRENAR EL MODELO -----------------\n",
    "# Entrenar el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predecir los resultados en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# ----------------- EVALUACIÓN DEL MODELO -----------------\n",
    "# Mostrar la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nPrecisión del modelo (accuracy):\", accuracy)\n",
    "\n",
    "# Mostrar reporte de clasificación\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525d108e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el pipeline de preprocesamiento\n",
    "joblib.dump(preprocessor, 'preprocessor_pipeline.pkl')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6067115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el pipeline de preprocesamiento\n",
    "preprocessor_loaded = joblib.load('preprocessor_pipeline.pkl')\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model_loaded = joblib.load('logistic_regression_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
